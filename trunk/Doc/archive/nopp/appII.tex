\renewcommand{\chaptertitle}{West Coast Regional Workshop}
\chapter{\texorhtml{}{Appendix B }\chaptertitle}

%% $Id$
 
\begin{center}
January 17th and 18th, 2001\\
Oregon State University\\
Corvallis, OR
\end{center}

\section{Executive Summary}

The science presentations on research in the California Current
highlighted a few key themes.  These include:
\begin{itemize}
\item Processes vary on a veriety of time and space space scales
  (e.g., local vs. remote forcing).
\item Mesoscale variability is an important component of the
  California Current.
\item Eastern boundary currents are productive biologically, and
  coupling with physical forcing is a critical issue.  In a sense,
  these issues are almost dogma, but they do lead to some common
  requirements for any data system:
\item Preservation and stewardship of data $\rightarrow$ time series are
  critical.
\item Integration across variety of data types $\rightarrow$
  biology/physics/chemistry.
\item Access by non-experts $\rightarrow$ managers as well as researchers who
  are not specialists with every data set.
\end{itemize}

Discussions during the workshop led to strong support for the idea of
a West Coast regional node, in addition to the local nodes.  The
regional node would provide services that would be beyond the
capabilities of a local node or would be done more efficiently at a
regional site.  Possible functions include:
\begin{itemize}
\item Data set certification - mechanisms to provide some degree of
  assurance of data quality for decades.
\item Data archaeology and rescue - many datasets are lacking homes.
\item Long-term archiving - when projects end, investigators retire, etc.
\item Advanced visualization services - display tools such as those
  developed at NOAA/PMEL as part of the Live Access Server
  (http://ferret.wrc.pmel.noaa.gov/las).
\item Define computer scenarios and output that might be made
  accessible (e.g., ENSO vs. non-ENSO model runs).
\end{itemize}

Participants at the workshop discussed possible local nodes that might form a 
cooperative, pilot study for the West coast.  The local nodes include:

\begin{itemize}
\item Scripps Institution of Oceanography
\item University of California, Santa Barbara
\item Pacific Fisheries Environmental Group
\item Monterey Bay Aquarium Research Institute
\item Naval Postgraduate School
\item University of California, Santa Cruz
\item San Francisco State University
\item Oregon State University
\item Pacific Marine Environmental Laboratory
\item University of Washington
\end{itemize}

In parallel, there are projects, some of which span multiple
institutions: California Cooperative Oceanic Fisheries Investigations
(CalCOFI), SIO Data Zoo, Mineral Management Service (MMS), Northeast
Pacific GLOBEC, Pacific Northwest Coastal Ecosystem Regional Study
(PNCERS), Partnership for Interdisciplinary Studies of Coastal Oceans
(PISCO), National Oceanographic Partnership Program (NOPP, which
includes multiple programs), and Coastal Oceanography Program (CoOP,
including COAST and WEST).  The point was not to list all possible
projects and all possible institutions, but to develop a
``reasonable'' list for a possible pilot study.

Datasets (again, not meant to be comprehensive) include: CTD,
moorings, drifters, ADCP, CODAR, SeaSoar/Scanfish, surface
meteorology, satellite imagery, chlorophyll, zooplankton biomass, and
nutrients.

Participants discussed the minimum set of semantic metadata that would
be necessary to use ``minimally'' processed data.  That is, we do not
expect people to serve raw volts from a sensor.  These are:

\begin{itemize}
\item Time and location - this will require an ancillary file that
  describes the time/space axes (e.g., latitude/longitude convention,
  time convention, etc.).
\item Descriptive variable name - including something that would
  indicate the sensor type.
\item Units
\item Missing data value - e.g., -9999, `NaN', etc.
\item Scaling, including slope/offset.
\end{itemize}

This information would allow a researcher to read in a data file and
know enough about it to conduct useful analyses of it.  It was noted
that the COARDS convention as part of the NetCDF standard would help
with naming, etc.  

See
\Url{http://www.unidata.ucar.edu/packages/udunits/index.html} for more
details.  

Also see
\xlink{http://ferret.wrc.noaa.gov/noaa\_coop/coop\_cdf\_profile.html}{http://ferret.wrc.noaa.gov/noaa_coop/coop_cdf_profile.html}.

A minimum set of metadata for data set discovery (that is, to help
users find datasets of interest) could be built up from the NASA
Global Change Master Directory (GCMD) which has an extensive set of
catalog information, standard terms, etc.  The GCMD is also willing to
help users describe their data holdings (see
\Url{http://gcmd.gsfc.nasa.gov/}).

For data presentation, it is often useful to provide palettes for
display of imagery, maps, sections, etc.  This would fall under the
category of presentation metadata.

Lastly, participants discussed information that would help ``certify''
datasets and increase user confidence.  This metadata would include:

\begin{itemize}
\item Publications based on the data set.
\item Calibration files.
\item Quality control procedures and description.
\item Comparisons with other data.
\item Error fields, caveats.
\item Processing algorithms.
\end{itemize}

These four ``layers'' (``use'' or semantic metadata, discovery metadata,
presentation metadata, and certification metadata) are all optional,
but the more layers a data provider delivers, the more useful the
data.  At a minimum, we expect that any data set in the pilot study
would provide the use/semantic metadata.  Other layers of metadata
could then be added on this base.

Participants recommended that endangered datasets critical for
California Current research be identified and a rescue plan developed
and implemented.  A plan for a West Coast DODS would build up a set of
local nodes and establish a regional, loosely coordinating node.

\section{Introductions and NOPP Objective}

The meeting convened with Mark Abbott, West Coast DODS regional
workshop coordinator, welcoming the workshop participants and then
asking everyone to introduce themselves (\sectionref{II,attendees}
lists the workshop participants).  He noted that there is an abundance
of data available to scientists (historic, etc.) and that the NOPP
project would facilitate greater data sharing.  Mark stated that he
wants to focus on science as it pertains to DODS in this workshop.

He presented the NOPP Objective: ``to easily access certain data types
in specified locations/times, regardless of data sources, and without
special efforts or insights on the part of the user about the data
sources.''

\subsubsection{VODHub (DODS) Workshop Issues}

During the course of the workshop, the following questions pertaining
to DODS would be addressed:
\begin{itemize}
\item Is the DODS data model adequate?  If not, what additions are
  required?
\item What are the user interface issues?  This should include basic
  functionality ranging from data discovery to data use.
\item What types of metadata are required?  The focus should be on
  search and use metadata.
\item What datasets will be served via DODS?  These may include fixed
  sets, region- specific sets, and missing sets.
\item Is a central regional node needed for coordination?
\end{itemize}

\subsubsection{West Coast Workshop Issues}

In addition to the VODHub issues above, the following specific issues
pertaining to the West Coast were to be discussed:
\begin{itemize}
\item Enhance dataset discovery, sharing, and access through the use
  of web-based servers and applications, not just DODS.
\item Increase the number of West Coast datasets available in readily
  usable format (include both historical and real-time).
\item Identify a suite of data types of special interest to West Coast
  researchers.
\item Foster collaboration of West Coast region-specific issues.
\end{itemize}

\subsubsection{Workshop Agenda and Guiding Principles}

The workshop agenda was as follows:

\begin{enumerate}
\item Presentations on DODS and Live Access Server (LAS) capabilities.
\item Presentations on research activities on the West Coast and
  available datasets.
\item Evaluation of data servers.
\item Future activities and demonstrations.
\end{enumerate}

Some of the guiding principles should include:

\begin{itemize}
\item Simplicity and endurance.
\item Gain user experience by starting early, starting small end-to-end systems.
\item Multiple sources of data and services.
\item Science involvement is essential.
\item Learn from experience.
\end{itemize}

\section{Overview of the DODS System}

Paul Hemenway, of the DODS technical staff at URI, summarized the DODS
concept with a graphical example.  He pointed out that DODS is a data
transfer mechanism that allows users access to data at different sites
and does it independently of data format.  Paul drew an example of a
DODS client accessing data over the web from a DODS server.

The floor was then turned over to James Gallagher, one of the
developers of DODS, who covered the underlying aspects of DODS and how
they relate to the workshop.  James covered the following issues:

\begin{itemize}
\item What types of metadata are required?
\item Level of architecture and design constraints of DODS.
\item The DODS protocol: capabilities and deficiencies.
\item Is the data model sufficient?   
\item DODS is an end-to-end system.
\end{itemize}

James began the overview of DODS by accessing the DODS demonstration
website
(\Url{http://po.gso.uri.edu/~dan/dods-regional-workshops/dods-regional-workshops.html}).
By going through a series of web pages, the DODS model concept was
conveyed to the workshop.  Some of the more important web pages are
highlighted below:

\paragraph{WEB PAGE}  What is DODS? 
\begin{itemize}
\item An architectural framework to allow a user to easily access data
  over the network in a consistent fashion.
\item DODS is an extension of the web.
\end{itemize}

\paragraph{WEB PAGE}  DODS can subset, acquire, and ingest data.  
\begin{itemize}
\item DODS does not locate or analyze data for a user.
\item DODS can move model and non-model data.  
\end{itemize}

As an aside, James pointed out that there are several levels of DODS
clients ranging from Matlab, Ferret, GRADS, and IDL to writing your
own client using languages such as C++ or Java.  It is also possible
to write applets to create clients.

\paragraph{WEB PAGE}  What DODS is not:
\begin{itemize}
\item An analysis package.
\item A data location service.
\item A web browser.
\item A tool to make value judgements with regard to data in the
  system. (Data quality is the responsibility of the provider AND of
  the user). But it is very easy to provide a listing of
  ``acceptable'' DODS datasets.
\end{itemize}

\paragraph{WEB PAGE}  Data level systems
\begin{itemize}
\item Directory level (Global Change Master Directory (GCMD) is a good example).
\item Inventory level (satellite data).
\item Data level.
\end{itemize}

DODS has been built from bottom up.  Other earth science systems are
built from the top down.  DODS focus is to build data transfer
functionality first and worry about inventory and directory
capabilities later.

\paragraph{WEB PAGE}  Underlying Philosophy of DODS
\begin{itemize}
\item Anyone willing to share their data should be able to so via DODS.
\item The user should be able to use the application package with
  which she or he is the most familiar to examine or analyze the data
  of interest.
\end{itemize}

\paragraph{WEB PAGE}  Metadata and Interoperability
\begin{description}
\item[Syntactic metadata] - information about the data type and
  structures at the computer level often referred to as the data model
  (the base level of information you need, in order to have something
  inside a computer).  
\item[Semantic metadata] - information about the content of the data
  (information about variables, etc.).
\end{description}

\paragraph{WEB PAGE}  Metadata relationships between levels - syntactic metadata
\begin{itemize}
\item The directory and inventory levels are generally subsets of that
  at the data level.
\end{itemize}

\paragraph{WEB PAGE} Metadata relations between levels - Semantic Metadata
At the data level (information needed to use the data):
\begin{itemize}
\item Parameter names (e.g. temperature).
\item Units (e.g. degrees centigrade).
\item Missing value parameter (e.g. -9999).
\end{itemize}

\paragraph{WEB PAGE}  At the directory level (information needed to locate datasets):
\begin{itemize}
\item Parameter ranges.
\item Parameter names.
\item Campaign.
\end{itemize}

\begin{description}
\item[Question:]  Where does DODS stand with federal metadata standards?
\item[Answer:] Some are currently served with metadata.  The group
  needs to decide on what metadata standard to use (FGDC, EPIC, etc.).
\end{description}

\paragraph{WEB PAGE}  Semantic metadata at the data level.
\begin{itemize}
\item Use metadata.
\item Directory level.
\end{itemize}

\paragraph{WEB PAGE}  Use Metadata.
\begin{description}
\item[Translational use metadata] - Metadata to translate dataset data
  objects to those with which the user is more familiar (e.g.,
  variable names, scaling of data values).  
\item[Descriptive use metadata] - Metadata that describes operations
  performed to obtain the delivered data.  
\end{description}

DODS focus is on translational use metadata.

\paragraph{WEB PAGE}  Levels of interoperability at the data level:
\begin{description}
\item[Level 0] - no syntactic or semantic metadata - FTP.
\item[Level 1] - rigid syntactic, no semantic metadata - DODS
\item[Level 2] - rigid syntactic, human readable semantic use
  metadata - A subset of DODS data sets.
\item[Level 3] - rigid syntactic, consistent semantic use metadata;
  i.e., machine-readable - A subset of the DODS Level 2 data sets.
\end{description}

\paragraph{WEB PAGE}  DODS supports three data objects:
\begin{enumerate}
\item Data descriptor structure - DDS  (syntactic metadata).
\item Data attribute structure  - DAS (semantic metadata).
\item Data (the actual data in a binary structure).
\end{enumerate}

In addition, DODS servers support several other services:
\begin{itemize}
\item .ascii, an ascii representation of the data.
\item .info, a more readable version of the .dds and .dat combined.
\item .html form, a web-based form that will help to build a DODS URL.
\end{itemize}  

James showed an example requesting WOCE TOPEX data from a DODS server.
The URL is passed to httpd via a DODS client.  The httpd server
receives the URL, passes it to the DODS server software, which reads
the data, and packages it to be returned to the client.  (Several
comments were made to the syntax that James was writing.)  It was
emphasized that \emph{writing DODS URLs can be difficult!}

Examples of the browser form and DODS dataset access form were
presented.  There were many comments on the content of the data
retrieved, such as latitude and longitude, as they relate to metadata.

\paragraph{WEB PAGE}  The DODS data model consists of the following data types:
\begin{itemize}
\item Byte
\item Integer
\item Short integer
\item Float
\item String
\item URL
\end{itemize}

And groupings of these data types:
\begin{itemize}
\item Array
\item Structure
\item List
\item Sequence (important for relational databases)
\item Grid (any array with axes of information that mean something)
\end{itemize}

A user can mix and match the above data types to represent any
possible data structure.  It was noted that satellite swath data is
difficult to represent in DODS.  Various array types and structures
(i.e., unstructured grid models) that workshop attendees worked with
were discussed.  James noted that handling complex arrays would likely
be a future enhancement to the DODS model.

\begin{description}
\item[Question:] For time varying, 3-D array datasets with many
  variables, how do users slice though the data to obtain time slice
  or level slice information?
\item[Answer:]  
\begin{enumerate}
\item For large datasets, where data are stored in HDF as ``chunked''
  data, it is possible to reach in and pull small sections out.  Model
  data is usually large and is typically stored in compressed
  granules.
\item Usually in multi parameter datasets, each parameter is stored in
  separate files, which means each has its own separate URL.
\end{enumerate}
\end{description}

Metadata about space and time is actually data in the dataset.
Latitude and longitude are easier to handle than time.

\paragraph{WEB PAGE}  Additional DODS core attributes include:
\begin{itemize}
\item De-referencing of DODS URLs in the constraint expression.
\item Server side functions.
\end{itemize}

James noted that space and time variables need to be handled in a
special way.

The File Server is a DODS accessible inventory of the files in a
multi-file dataset.

\paragraph{WEB PAGE}  The Aggregation Server was still in beta development (available in two 
months).

\paragraph{WEB PAGE}  DODS - Dir
\begin{itemize}
\item Uses a browser to run through a collection of files.
\item When the URL ends in a ``/'', this indicates that it is a directory.
\end{itemize}

\paragraph{WEB PAGE}  Client and server status graphic (see the DODS website for details).
Also, an analysis server for GRADS and SQL are available.

\subsection{Examples and Demos}

\subsubsection{First Demo}

James went to the Global Change Master Directory (GCMD) website.  He used the 
GCMD to find several DODS datasets.  Using the metadata provided, a DODS URL was 
selected.  The following procedures were used:

\begin{enumerate}
\item The URL was pasted into Matlab.
\item Data were obtained from a remote site, and imported into Matlab
  using the LOADDODS command.
\item Sea surface temperature was plotted in a GUI window.
\item A sub-sample was performed to get every 16th value.
\end{enumerate}

\begin{description}
\item[Question:]  Is the image data type served by DODS?
\item[Answer:] Animation and image formats are not served by DODS.
  James thought it should be added in the future.  Some users want
  this functionality.
\end{description}

\subsubsection{Second Demo}

James used Matlab and Level 3 metadata to create an image of sea
surface temperature (an example of Level 3 interoperability).  The
interface constructed the constraint based on geographic and time data
and, as a result, variables were created.  Other functionality was
demonstrated.

\begin{description}
\item[Question:] How does DODS differ from JGOFS (as it pertains to
  the NE GLOBEC program)?
\item[Answer:] Data management systems and data delivery systems are
  different.
  
\item[Question:] Are there security issues (e.g., breaking in or
  corrupting datasets)?
\item[Answer:] There are different levels.
\begin{enumerate}
\item Modifying your data files (but DODS is read-only so it is
  difficult to corrupt your data).
\item PERL is insecure on the web.
\item C++ software is more secure.
\item Security support exists but is not great right now.
\end{enumerate}
\end{description}

\subsection{Demonstration of the Live Access Server (LAS)}

Jon Callahan - PMEL

Several examples of the LAS were given by accessing data using a web
browser and using Ferret:

\begin{enumerate}
\item Displayed SODA data.
\item Pacific Fisheries Environmental Lab (did not connect).
\item Carbon Modeling Consortium (CMC) website.
\item Displayed CO2 emissions data for Mauna Loa. 
\item Displayed ship tracking.
\end{enumerate}

Comments:

\begin{enumerate}
\item LAS provides useful visualizations of data.
\item The data provider needs to know how to present data.  
\item The niche for LAS is data browsing.
\item Ferret is hard to use.
\item Prefers NetCDF format.
\item Jon could possibly put West Coast datasets up on the LAS, given
  funding.
\end{enumerate}

\begin{description}
\item[Question:]  Are there other interfaces?
\item[Answer:]  No other interfaces other than the web browser.
\end{description}

\section{Science Presentations and Related Regional Datasets}

 (see \sectionref{II,urls}
for important websites)

\subsection{Jane Huyer - OSU}

 (used overheads)

Dataset listing:
\begin{enumerate}
\item CTD sampling (3 and 5 times per year).
\item Satellite track.
\item GLOBEC LTOP in NCCS
\item CTD, biochemistry, Drifters, mooring, ADCP, mocness, vertical
  nets, towed acoustics.
\end{enumerate}


The goal is to look at long-term climate change.  Interested in long term and 
vulnerability.

\paragraph{OVERHEAD} - Example of five seasonal means.

\paragraph{OVERHEAD} - El Ni\~no September temperature graph.

\paragraph{OVERHEAD} - Derived data set.

Would like to make current meter data readily accessible.


\subsection{Jerry Wanetick - SIO}

(web presentation, www.ccs.ucsd.edu/zoo)

Center for Coastal Studies (CCS) Data Zoo Contents (see \sectionref{II,zoo})

Note:  Table of Non-Zoo CCS data is not available at the website. (but
see table~\ref{II,table1} \texorhtml{on \pageref{II,table1}}{}.

At the website: 
\begin{itemize}
\item Showed directory of data.
\item All data is formatted into ASCII.
\item Data could be served using a FreeForm server.
\item All time series data are in ASCII.
\end{itemize}

Community information node to get information about regional data.
\begin{itemize}
\item Would list performance of server, etc.
\item Data may need to be certified for making it usable.
\item Some people may not want to do this.
\end{itemize}

\paragraph{WEB PAGE} Plotted drifter data. (Jerry noted that SIO is putting together a catalog 
showing how each have been released).

\paragraph{WEB PAGE}       Showed drifter trajectory image.

\paragraph{WEB PAGE}       Displayed meteorological data.

\paragraph{WEB PAGE}        Showed current and temperature observation data.

\paragraph{WEB PAGE}       Displayed de-tided data.

\paragraph{WEB PAGE}       Displayed current meter data.

Comments:
\begin{itemize}
\item Possibly have a server that gives a user data in various formats
  (de-tided, raw, avg., etc.) and then creates a view of the dataset.
\item Regional node function (certification, community kinds of
  things)?
\end{itemize}

\paragraph{WEB PAGE}       ADCP data displayed from website.

\paragraph{WEB PAGE}       Data broken up by depth.

CCS Data, Zoo Data Characteristics:
\begin{itemize}
\item Heavy on velocity and temperature time series.
\item Hourly averages mostly. 
\item Missing data:
\begin{itemize}
\item Shipboard ADCP from CODE, SMILE, etc.
\item Incomplete CTD data from SMILE.
\item Big holes in SuperCODE (only partial CTD).
\end{itemize}
\item 4-minute averages available for SBCSMB \& NCCCS.
\item High frequency ADCP \& pressure data from Iwaves.
\item SMILE 7.5-minute data, possibly still at WHOI (may need to rescue soon).
\end{itemize}

CCFS Data, Zoo Science Issues:
\begin{itemize}
\item Hourly average data preclude internal wave studies.
\item Description of seasonal cycles of temperature and velocity for
  the West Coast shelf.
\item Response to wind forcing on the West Coast.
\begin{itemize}
  \item Analysis of remote forcing (coastal trapped waves) for the
  entire West Coast.  
\item Study the relative roles of local and
  remote wind forcing along the West Coast.
\end{itemize}
\item Abundant data available to estimate tidal constituents for
  currents all along the West Coast.  
\begin{itemize}
\item A high- resolution tide
  model including data assimilation of both velocities and sea level.
\item De-tiding satellite altimetry and shipboard ADCP coastal
  data.  
\item Internal tide climate (barotropic tide model -
  observed currents) following Foreman et al. (Dec 15, 2000 JGR).
\end{itemize}
\end{itemize}

\subsection{Hal Batchelder - OSU/COAS}

(used overheads)

The focus of his work is on GLOBEC data.

\paragraph{OVERHEAD} - Showed a listing of nineteen datasets, the area
covered, time period, and data source.

\paragraph{OVERHEAD} - Graphic of time series of three fish species.

\paragraph{OVERHEAD} - Graphic of larval ship surveys.

\paragraph{OVERHEAD} - Graphic of geographic distribution.

\paragraph{OVERHEAD} - Graphic of 3-5 time visitation.

\paragraph{OVERHEAD} - Graphic of long term sampling.

\paragraph{OVERHEAD} - Graphic showing Gulf of Alaska GLOBEC monitoring stations.

Comments:
\begin{itemize}
\item Lots of surface information, long-track, etc. have been collected.
\item Lots of other miscellaneous datasets have been collected.
\item Hard models to distribute.
\item There is a need to make models available to other researchers.
\item Lots of these models are going on in research groups, but how to
  share this data is key (near-line storage vs. on-line storage).
\end{itemize}

\subsection{Corrine James - OSU}

Oregon State's Satellite Archive for the NE Specific US GLOBEC Program (website).

Comments:

\begin{itemize}
\item Has a large archive of satellite data.
\item Long- range plan is to serve up AVHRR high resolution data.
\item Pathfinder data is available.
\item Will add SeaWiFS data in the future.
\item Data resides in a sequel server database.
\item Data is gridded to Level 3.
\item 1 kilometer resolution.
\end{itemize}

\subsection{Mark Abbott - OSU}

Remote Sensing Ocean Optics

(presentation from website,
\Url{http://nugget.oce.orst.edu/ORSOO/oregon/drifters})

Mark noted that data files are available via ftp through a web interface.

\paragraph{WEB PAGE}       WOCE style drifter (follows current, not wind).

There have been two sets of deployments:

\paragraph{WEB PAGE}       Displayed plots of drifters.

\paragraph{WEB PAGE}       Displayed data files (3000 points in a file).

\paragraph{WEB PAGE}       Satellite Dish Installation. (Installed an x-band receiving station.)

\paragraph{WEB PAGE}       Showed coverage of OSU satellite dish.

Comments by Mark:
\begin{itemize}
\item The web is good for quick requests for data.
\item People are moving to near real-time on West Coast.
\item Data provider issues need to be addressed.
\item A lot of data from the southern oceans.
\begin{itemize}
\item Moorings.
\item Older California drifter data.
\item Some profile data.
\end{itemize}
\end{itemize}

\subsection{Brian Schlining - MBARI}

 (used overheads).

The primary questions the staff at MBARI seek to answer are:
\begin{enumerate}
\item What are the mean and fluctuation components of phytoplankton primary production, 
biomass, and species composition on time scales ranging from days to years?
\item What are the physical, chemical, and biological processes responsible for the mean 
and fluctuating components?
\item What controls primary production and phytoplankton growth rates?
\item What is the role of meso and microzooplankton in coastal upwelling systems?
\item What is the fate of primary production?
\item What are the biological consequences of El Ni\~no?
\end{enumerate}


Scientific questions:
\begin{enumerate}
\item What are the physical links between the Tropical Pacific and the
  California Current, and what are their characteristic time and space
  scales?
\item What alternate physical processes affect the California Current
  at these characteristic scales?
\item What are the relative roles of mesoscale versus basin-scale
  dynamics in forcing ecosystem variability?
\item By which processes do physical forcing regulate ecosystem
  dynamics at seasonal, interannual and decadal time-scales?
\item By which processes do physical forcing regulate ecosystem
  structure and bio-diversity?
\end{enumerate}


\paragraph{OVERHEAD} - Overall display of El Ni\~no.

\paragraph{OVERHEAD} - Display of El Ni\~no bloom.

Brian noted that MBARI is putting together an El Ni\~no notebook.

\paragraph{OVERHEAD} - Showing buoys, moorings, and drifter data.

\paragraph{OVERHEAD} - Showing master plan.

Brian next went to the MBARI website to show what datasets are available:
\begin{itemize}
\item OASIS Mooring data
\item Wind data
\item CTD data
\item Barometer data
\end{itemize}

He mentioned that all the datasets would be available through DODS in the next few 
weeks.


\subsection{Toby Garfield - San Francisco State University}

(used overheads)

Data types available:
\begin{itemize}
\item Mooring data (at Scripps)
\item Meteorology
\item CODAR
\item Ship-based (CTD)
\item Bottle/Net
\item Underway data:
\begin{itemize}
\item ADCP.
\item Scanfish.
\item Floats.
\item Drifters.
\item Modeling.
\item Pioneer Seamount for broadband acoustic data.
\item CalCOOS (potential dataset).
\item CIRSI.
\end{itemize}
\end{itemize}

\section{Server Issues}

\begin{description}
\item[Question:]  What does it take to build a DODS server?

As an example, CTD data (from Jerry's Data Zoo) was used.  The CTD data has the 
following attributes:
\begin{itemize}
\item Currently they are flat ASCII files.
\item Have a header file.
\item Have other information in an ancillary file.
\end{itemize}
\end{description}

James Gallagher suggested to use the FreeForm server for CTD (columnar
data).  However, he noted that NetCDF is easier to configure, as
opposed to FreeForm which needs a special configuration script to read
columnar data.  A lot of discussion and questions arose about handling
this kind of data.

Some of the questions included:
\begin{description}
\item[Question:]  Does NetCDF require EPIC convention metadata?
\item[Answer:]  NO.
  
\item[Question:] What happens to your data files if there is sensor
  dropout, when you are using FreeForm?
\item[Answer:] The URI staff has had some experience with this but not
  sure what would happen.
  
\item[Question:] How long would it take to get a FreeForm server up
  and running for Jerry's data?
\item[Answer:] If the FreeForm server exists on the machine with data,
  the format file and additional files could be formatted in one hour.
  
\item[Question:] How do you tell DODS how your data is laid out?
\item[Answer:] It depends on which server you want to use and how your
  data is laid out.  The servers don't inherently understand directory
  structure.  JGOFS can traverse hierarchical collections of files.
  James is not sure if FreeForm can cross multiple data files.
  
\item[Question:] What is the next step to turn on a DODS server?
\item[Answer:] Put the executable in a directory along with other
  files in certain directories.
  
  Installation of the servers is handled automatically.  James noted
  that the FreeForm server is the most complicated server to set up.
  
\item[Question:] Can you get metadata from FreeForm?
\item[Answer:] You get no semantic metadata.  It must be written up in
  a structured text object.  The metadata goes into a third file.
  
\item[Question:] Is the format for FreeForm in DODS documentation
  presented with examples?
\item[Answer:] Yes, and there are examples.
\end{description}

James compared and contrasted JGOFS and NetCDF.  He noted that JGOFS
can be tailored quite easily to handle your data.

Supported DODS Servers (user software products):
\begin{itemize}
\item NetCDF
\item HDF 4 (HDF.EOS)
\item DSP
\item Matlab
\item FreeForm
\item JGOFS
\item RDBS (anything using JDBC)
\end{itemize}

Servers not supported:
HAO, GRIA, GrADS, WMT (Gateway)

There is a user guide for the FreeForm server.

\begin{description}
\item[Question:]  Are there unique issues concerning satellite data?
\item[Answer:] Anything below level 3 would be difficult.  Swath data
  is difficult.
  
\item[Question:] What about .jpg and .gif images?
\item[Answer:] These file types are easily viewed in a browser.
\end{description}

Comment:
Large format files, like towed acoustic data, need to be put into NetCDF format.

\begin{description}
\item[Question:] What are the maintenance issues and efforts involved
  once someone has established a DODS server?
\item[Answer:] URI tries to make sure configuration files never need
  to be changed.  Unidata provides user support.
\end{description}

\subsubsection{Is the DODS data model adequate?}

There were no major deficiencies noted.  Acoustic data and animation
capabilities were issues that would be tackled at a later date.

\section{The California Current System}

Throughout the science presentations, a few key themes emerged.

California Current System research issues:
\begin{itemize}
\item Processes vary on long time and large space scales (e.g., local
  vs. remote forcing).
\item Mesoscale variability is an important component.
\item Eastern boundary currents are productive biologically, and
  coupling with physical forcing is a critical issue.
\end{itemize}

In a sense, these issues are almost dogma, but they do lead to some common 
requirements for any data system:
\begin{itemize}
\item Preservation and stewardship of data $\rightarrow$ time series are critical.
\item Integration across a variety of data types $\rightarrow$ bio/phys/chem.
\item Access by non-experts $\rightarrow$ managers as well as researchers who
  are not specialists with every data set.
\end{itemize}

\section{Organization Issues}

\subsection{Regional Node}

Group discussion led to strong support for the idea of a West Coast
regional node, in addition to the local nodes (discussed below).  The
regional node would provide services that would be beyond the
capabilities of a local node or would be done more efficiently at a
regional site.  Possible functions include:
\begin{itemize}
\item Data set certification - mechanisms to provide some degree of
  assurance of data quality for decades.
\item Data archaeology and rescue - many datasets are lacking homes.
\item Long-term archiving - when projects end, investigators retire, etc.
\item Advanced visualization services - display tools such as those
  developed at NOAA/PMEL as part of the Live Access Server.
  (\Url{http://ferret.wrc.pmel.noaa.gov/las})
\item Define computer scenarios and output that might be made
  accessible (e.g., ENSO vs.  non-ENSO model runs).
\end{itemize}

\subsection{Datasets and Nodes}

The workshop participants briefly discussed possible local nodes that might form a 
cooperative pilot study for the West Coast.

\begin{itemize}
\item SIO
\item UCSB
\item PFEG
\item MBARI
\item NPS
\item UCSC
\item SFSU
\item OSU
\item PMEL
\item UW
\end{itemize}

In parallel, there are projects, some of which span multiple
institutions: CalCOFI, SIO Data Zoo, MMS, GLOBEC, PNCERS, PISCO, NOPP
(multiple programs), CoOP (COAST and WEST).  The point was not to list
all possible projects and all possible institutions, but to develop a
``reasonable'' list for a possible pilot study.

Datasets (again, not meant to be comprehensive) include: CTD,
moorings, drifters, ADCP, CODAR, SeaSoar/Scanfish, surface
meteorology, satellite imagery, chlorophyll, zooplankton biomass, and
nutrients.

\subsection{Metadata and Data Services}

Participants discussed the minimum set of semantic metadata (in the
DODS vernacular) that would be necessary to use ``minimally''
processed data. That is, we do not expect people to serve raw volts
from a sensor. These are:

\begin{itemize}
\item Time and location - this will require an ancillary file that
  describes the time/space axes (e.g., lat/lon convention, time
  convention, etc.).
\item Descriptive variable name, including something that would
  indicate the sensor type.
\item Units.
\item Missing data value - e.g., -9999, NaN, etc.
\item Scaling, including slope/offset.
\end{itemize}

This information would allow a researcher to read in a data file and
conduct useful science.  It was noted that the COARDS convention as
part of the NetCDF standard would help with naming, etc.  See
\Url{http://www.unidata.ucar.edu/packages/udunits/index.html} for more
details.  Also see
\xlink{http://ferret.wrc.noaa.gov/noaa\_coop/coop\_cdf\_profile.html}{http://ferret.wrc.noaa.gov/noaa_coop/coop_cdf_profile.html}.

A minimum set of metadata for dataset discovery (that is, to help
users find datasets of interest) could be built up from the NASA
Global Change Master Directory (GCMD) which has an extensive set of
catalog information, standard terms, etc.  The GCMD is also willing to
help users describe their data holdings (see
\Url{http://gcmd.gsfc.nasa.gov/}).

For data presentation, it is often useful to provide palettes for
display of imagery, maps, sections, etc.  This would fall under the
category of presentation metadata.

Lastly, we discussed information that would help ``certify'' datasets
and increase user confidence.  This metadata would include:
\begin{itemize}
\item Publications based on the data set.
\item Calibration files.
\item Quality control procedures and description.
\item Comparisons with other data.
\item Error fields, caveats.
\item Processing algorithms.
\end{itemize}

These four ``layers'' (``use'' or semantic metadata, discovery metadata,
presentation metadata, and certification metadata) are all optional,
but the more layers a data provider delivers, the more useful the
data.  At a minimum, we expect that any dataset in the pilot study
would provide the use/semantic metadata.  Other layers of metadata
could then be added on this base.


\section{Attendees}
\label{II,attendees}

\begin{center}
West Coast DODS Regional Workshop
January 17th and 18th, 2001
Attendee List
\end{center}

\begin{center}
  \begin{tabular}[t]{llll} \\
\textbf{Name} & \textbf{Organization} & \textbf{Phone} & \textbf{Email} \\
Mark Abbott &             COAS/OSU               & (541)737-4045         &  mark@oce.orst.edu \\
Hal Batchelder &          COAS/OSU               & (541)737-4500         &  hbatchelder@oce.orst.edu \\
Eric Beals &              OSU                    & (541)737-4548         &  beals@oce.orst.edu \\
Jon Callahan &            NOAA/PMEL              & (206)526-6801         &  callahan@pmel.noaa.gov \\
Jane Fleischbein &                OSU                    & (541)737-5698         &  flei@oce.orst.edu \\
Jim Fritz &                       TPMC                   & (781)545-1346         &  jfritz@tpmc.com \\
James Gallagher &         URI                    & (541)757-7992         &  jgallagher@gso.uri.edu \\
Toby Garfield &           SFSU-RTC               & (415)338-3713         &  garfield@sfsu.edu \\
Paul Hemenway &           URI                    & (401)874-6677         &  phemenway@gso.uri.edu \\
Jane Huyer &              OSU                    & (541)737-2108         &  ahuyer@oce.orst.edu \\
Corinne James &           OSU                    & (541)737-2270         &  corinne@oce.orst.edu \\
Mike Korso &              COAS/OSU               & (541)737-3079         &  kosro@oce.orst.edu \\
Nathan Potter &           OSU                    & (541)737-2293         &  ndp@oce.orst.edu \\
Brian Schlining &         MBARI                  & (831)775-1855         &  brian@mbari.org \\
Ted Strub &               OSU                    & (541)737-3015         &  tstrub@oce.orst.edu \\
Jerry Wanetick &          SIO                    & (858)534-7999         &  jwanetick@ucsd.edu \\
  \end{tabular}
\end{center}


\section{Select HTTP References}
\label{II,urls}

\begin{description}
\item[NASA Global Change Master Directory]
\Url{http://gcmd.gsfc.noaa.gov/cgi-bin/}

\item[NOAA PMEL LAS Examples]
\Url{http://ferret.wrc.noaa.gov/nopp/main.html}

\item[SIO Data Zoo]
\Url{http://www.ccs.ucsd.edu/zoo}

\item[GLOBEC Satellite Data]
\Url{http://coho.oce.orst.edu}

\item[GLOBEC Drifter Data]
\Url{http://nugget.oce.orst.edu/ORSOO/oregon/drifters}

\item[DODS]
\Url{http://unidata.ucar.edu/packages/dods}

\item[DODS Documentation]
\Url{http://top.gso.uri.edu/}

\item[DODS Workshop Presentations]
\Url{http://po.gso.uri.edu/~dan/dods-regional-workshops/dods-regional-workshops.html}

\item[MBARI]
\Url{http://www.mbari.org}

\item[NOAA PMEL LAS]
\Url{http://www.coho.oce.orst.edu}

\item[NOAA PMEL LAS]
\Url{http://www.ferret.noaa.gov/Ferret/LAS}

\item[DODS HOME]
\Url{http://unidata.ucar.edu/packages/dods/  (home page)}

\item[GLOBEC]
\Url{http://globec.oce.orst.edu}

\item[GCMD]
\Url{http://www.gcmd.gsfc.nasa.gov}
\end{description}

\section{CCS Data Zoo Contents}
\label{II,zoo}

\begin{longtable}{|p{0.75in}|p{0.75in}|p{1.0in}|p{1.25in}|p{0.75in}|}
  \caption{CCS Data Zoo.\label{II,table1}}
\\ \hline
\textbf{Project} & \textbf{Sponsor/ Contractor} & \textbf{Region} &
      \textbf{Data Types} &    \textbf{Dates} \\ \hline
\endfirsthead
\caption{CCS Data Zoo (continued).}
\\ \hline
\textbf{Project} & \textbf{Sponsor/ Contractor} & \textbf{Region} &
      \textbf{Data Types} &    \textbf{Dates} \\ \hline
\endhead
\hline
\endfoot
CAMP &
MMS/SAIC &
Pt. Conception &
Currents &
April 1992 - July 1994 \\ \hline
CCCCS (Central California Coastal Circulation Study) &
MMS/Ray\-theon &
Pt. Conception to 
San Francisco &
\begin{tablelist}
\item Moored Currents
\item CTD
\item Drifters
\item Sea Level (NOS)
\item Met
\item IR Sat 
\item XBT (unavailable) 
\end{tablelist} &
Feb 1984 - July 1985 \\ \hline
CODE (Coastal Ocean Dynamics Experiment) &
NFS/NCAR, NOAA, USGS, WHOI, SIO, OSU, UNH &
Pt. Reyes to Pt. Arena &
\begin{tablelist}
\item Moored Currents
\item CTD
\item Drifters
\item Met
\item XBT (unavailable)
\end{tablelist} &
April 1981 - August 1982 \\ \hline
CTZ (Coastal Transition Zone) &
ONR/OSU, NPS &
N. California &
ADCP &
1987 \\ \hline
Del Mar Temperatures &
&
Del Mar, CA &
Temperatures 
(Thermistor Chains) &
1978 \\ \hline
SBCSMB (Santa Barbara Channel, Santa Maria Basin Study) &
MMS/SIO &
Santa Barbara 
Channel, Santa 
Maria Basin &
\begin{tablelist}
\item Moored Currents
\item CTD (Survey, Moored)
\item Drifters
\item Met
\item XBT
\item ADCP (Survey, Moored)
\item Bottom Pressure
\item NDBC Met \& ADCP
\item AVHRR
\end{tablelist} &
April 1992 - Present \\ \hline
NCCCS (Northern California Coastal Circulation Study) &
MMS, EG\&G, and SIO &
San Francisco - Oregon Border &
\begin{tablelist}
\item Moored Currents
\item CTD (Survey, Moored)
\item Drifters
\item Met
\item XBT
\item Bottom Pressure
\end{tablelist} &
1986 - 1989 \\ \hline
OPUS (Organization of Persistent Upwelling Structures) &
NSF/OSU &
Pt. Conception - Pt. 
Arguello &
\begin{tablelist}
\item Moored Currents 
\item CTD
\item Drifters
\item Met
\item XBT
\item Bottom Pressure
\item Sea Level
\end{tablelist} &
Pilot: March - April 1981
Main: April - July 1983 \\ \hline
SBC (Santa Barbara Channel Study) &
MMS/SAIC, Dyanlysis of Princeton &
Santa Barbara 
Channel &
\begin{tablelist}
\item Moored Currents
\item CTD (Survey, Moored)
\item Drifters
\item Met
\item Bottom Pressure
\end{tablelist} &
Jan 1984 - Jan 1985 \\ \hline
SMILE (Shelf Mixed Layer Experiment) &
NSF/WHOI &
Pt. Reyes - Pt. Arena &
\begin{tablelist}
\item Moored Currents
\item CTD (Survey, Moored)
\item ADCP (Survey)
\item Met
\item Thermistor Chains
\item Sea Level
\end{tablelist} &
Nov 1988 - May 1989 \\ \hline
\end{longtable}

\begin{longtable}{|p{0.75in}|p{0.75in}|p{1.0in}|p{1.25in}|p{0.75in}|}
  \caption{non-Zoo CCS Data.\label{II,table2}}
\\ \hline
\textbf{Project} & \textbf{Sponsor/ Contractor} & \textbf{Region} &
      \textbf{Data Types} &    \textbf{Dates} \\ \hline
\endfirsthead
\caption{non-Zoo CCS Data (continued).}
\\ \hline
\textbf{Project} & \textbf{Sponsor/ Contractor} & \textbf{Region} &
      \textbf{Data Types} &    \textbf{Dates} \\ \hline
\endhead
\hline
\endfoot
CDIP (Coastal Data Information System) &
USACOE-CDBW/SIO &
West Coast, Hawaii, East Coast (couple of stations) &
Wave direction and 
energy spectra &
1977 - Present \\ \hline
Iwaves &
ONR/SIO &
San Diego County &
Bottom-mounted 
upward-looking ADCP 
\& Temperature &
1998-1999 \\ \hline
Swash2000, BSRip, Undertoad &
ONR/SIO &
La Jolla &
Numerous nearshore 
wave, current, run-up, 
sonic altimeter and bed 
stress measurements &
1980 - present \\ \hline
NSTS (Nearshore Sediment Transport Study) &
USACOE &
Torrey Pines, SD Co,
Santa Barbara &
Numerous nearshore 
wave, current, run-up, 
dye injection and bed 
stress measurements &
1977, 1980 \\ \hline
CCSTWS (Coast of California Storm and Tidal Wave Study) &
USACOE &
Dana Point - 
Mexican Border &
Sub-areal and 
bathymetric survey 
transects of the beach 
and nearshore region &
1980 - 1982 \\ \hline
\end{longtable}



%%% Local Variables: 
%%% mode: latex
%%% TeX-master: t
%%% End: 
